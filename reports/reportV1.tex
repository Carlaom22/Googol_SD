\documentclass{article}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{float}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{titlesec}
\usepackage{hyperref}
\usepackage{tabularx}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{tabularx}
\usepackage{booktabs}
\geometry{a4paper, portrait, margin=1in}
\setstretch{1.25}
\pagestyle{fancy}
\fancyhf{}
\rhead{Sistemas Distribuídos}
\lhead{Meta 1}
\rfoot{\thepage}
\usepackage{listings}
\usepackage{xcolor}
\lstset{
    basicstyle=\ttfamily\small,
    keywordstyle=\color{blue}\bfseries,
    commentstyle=\color{gray}\itshape,
    stringstyle=\color{orange},
    numbers=left,
    numberstyle=\tiny\color{gray},
    stepnumber=1,
    breaklines=true,
    frame=single,
    tabsize=2,
    showstringspaces=false,
    captionpos=b
}
\titleformat{\section}{\normalfont\Large\bfseries}{\thesection.}{1em}{}
\titleformat{\subsection}{\normalfont\large\bfseries}{\thesubsection.}{1em}{}
\begin{document}

\begin{titlepage}
    \centering
    \vspace*{1cm}

    \includegraphics[width=0.4\textwidth]{imagens/dei_thumb.png}

    \vspace{1.5cm}
    {\LARGE \textbf{Meta 1 - Relatório Técnico} \par}
    \vspace{0.5cm}
    \vspace{2.5cm}
    \textbf{Licenciatura em Engenharia Informática} \\
    \textbf{Sistemas Distribuídos}

    \vspace{3cm}
    \begin{tabular}{ll}
        \textbf{Carlos Soares} & 2020230124, uc2020230124@student.uc.pt \\
        \textbf{Miguel Machado} & 2020222874, uc2020222874@student.uc.pt 
    \end{tabular}

    \vfill
    {\large \today \par}
\end{titlepage}



\newpage
\tableofcontents
\newpage



\section{Introdução}

Este relatório apresenta o desenvolvimento de um sistema distribuído para indexação e pesquisa de páginas web, desenvolvido no contexto da unidade curricular de Sistemas Distribuídos da Licenciatura em Engenharia Informática. O principal objetivo do projeto é aplicar, de forma prática, conceitos fundamentais da disciplina como comunicação remota, concorrência, tolerância a falhas, replicação e modularidade.

A solução foi implementada em Java, utilizando RMI (Remote Method Invocation) como tecnologia base de comunicação entre os diversos módulos distribuídos. A arquitetura do sistema é composta por vários componentes independentes e cooperantes: cliente de pesquisa, gateway de distribuição, servidores de armazenamento (barrels), gestores de fila centralizada de URLs e crawlers responsáveis pela recolha e análise de páginas web.

O sistema foi concebido para funcionar de forma concorrente e tolerante a falhas, com múltiplos crawlers a operar em paralelo e os dados replicados de forma atómica entre os diferentes barrels. Os dados são também guardados localmente, assegurando persistência e recuperação após falhas ou reinícios.

Neste documento são descritas as principais decisões de arquitetura, os mecanismos de replicação e sincronização entre nós, os testes realizados, bem como o funcionamento detalhado de cada componente. 
O trabalho desenvolvido cumpre, na sua maioria, os objetivos definidos para a primeira meta do projeto, demonstrando uma abordagem sólida.


















\newpage
\section{Objetivos do Projeto}
O desenvolvimento deste sistema teve como propósito a construção de uma aplicação distribuída robusta, escalável e tolerante a falhas, com funcionalidades completas de recolha, indexação, armazenamento e pesquisa de páginas web. 
\newline Para tal, foram definidos os seguintes objetivos específicos:

\begin{itemize} 
\item \textbf{Permitir a pesquisa de termos por parte dos utilizadores}, com apresentação dos resultados de forma ordenada consoante a sua relevância, baseada no número de ligações recebidas de outras páginas (backlinks);
\item \textbf{Implementar um processo de indexação recursiva e automática}, a partir de URLs inseridos pelo utilizador, de modo a explorar e processar todos os links internos presentes nas páginas web;

\item \textbf{Disponibilizar funcionalidades adicionais de consulta}, tais como a visualização da lista de páginas que referenciam uma determinada URL (backlinks), e estatísticas de utilização do sistema, incluindo os termos mais pesquisados e o tempo médio de resposta;

\item \textbf{Assegurar tolerância a falhas}, garantindo que a aplicação se mantém funcional mesmo perante a indisponibilidade temporária de alguns dos seus componentes, nomeadamente os servidores de armazenamento (barrels);

\item \textbf{Distribuir a carga entre múltiplos servidores de armazenamento}, implementando mecanismos de balanceamento que otimizem a utilização dos recursos disponíveis;

\item \textbf{Permitir a execução paralela de múltiplos crawlers}, com isolamento e independência, assegurando a eficiência na recolha e indexação de conteúdos web;

\item \textbf{Assegurar persistência dos dados}, garantindo que toda a informação indexada é armazenada localmente de forma segura e é recuperada automaticamente após falhas ou reinicializações do sistema.

\end{itemize}



















\newpage
\section{Componentes do Sistema}

O sistema foi estruturado de forma modular e distribuída, promovendo independência entre componentes e comunicação remota via Java RMI. Os principais módulos são:

\begin{itemize} \item \textbf{SearchClient}: Interface textual utilizada pelo utilizador para pesquisar termos, consultar backlinks, estatísticas, adicionar links e visualizar barrels ativos.

\item \textbf{SearchGateway}: Responsável por encaminhar pedidos para os barrels disponíveis, realizando balanceamento de carga e deteção de falhas.

\item \textbf{IndexStorageBarrel}: Servidores de armazenamento que mantêm o índice invertido, backlinks e estatísticas. Executam persistência local e replicação de dados para garantir tolerância a falhas.

\item \textbf{WebCrawler}: Agentes responsáveis por recolher conteúdo web e enviar para os barrels. Suportam execução paralela, scraping com JSoup e envio atómico para múltiplos barrels.

\item \textbf{CentralURLQueue}: Fila central de URLs partilhada por todos os crawlers. Garante que cada URL é processado uma única vez e permite adição de novos links.

\item \textbf{SearchService e SearchGateway (Interfaces RMI)}: Definem as operações remotas disponíveis nos barrels e na gateway, respetivamente.

\item \textbf{SearchServiceImpl e SearchGatewayImpl}: Implementações concretas das interfaces RMI, com tratamento de concorrência e falhas.

\item \textbf{LinkAdder}: Aplicação auxiliar que permite ao utilizador adicionar URLs à fila. Cada novo link origina o lançamento de um \texttt{WebCrawler} dedicado.

\item \textbf{run.bat}: Script de arranque que compila o projeto e inicia automaticamente todos os componentes do sistema em terminais distintos.
\end{itemize}






















\newpage
\section{Funcionamento Geral}

O sistema segue uma arquitetura modular com comunicação remota entre componentes, permitindo a indexação e pesquisa de páginas web de forma distribuída, tolerante a falhas e paralela.

\subsection{Indexação}

\begin{enumerate}
    \item O utilizador insere um URL no cliente (\texttt{SearchClient}).
    \item O link é adicionado à \texttt{CentralURLQueue}, que evita duplicações.
    \item Um \texttt{WebCrawler} é lançado automaticamente numa nova thread.
    \item O crawler obtém a página com JSoup, extrai o texto e os links.
    \item Os dados são enviados para todos os barrels (multicast atómico).
    \item Cada barrel atualiza o seu índice invertido e backlinks.
\end{enumerate}

Este processo é concorrente: múltiplos crawlers podem trabalhar em paralelo sem conflitos, graças à centralização da fila.

\subsection{Pesquisa}

\begin{enumerate}
    \item O utilizador pesquisa um termo no cliente.
    \item O pedido é enviado para a \texttt{SearchGateway}.
    \item Um barrel é escolhido automaticamente (round-robin).
    \item O índice é consultado e os resultados ordenados por número de backlinks.
    \item Os resultados são apresentados em grupos de 10.
\end{enumerate}

A gateway reencaminha o pedido se um barrel estiver offline, garantindo disponibilidade.

\subsection{Outras Funcionalidades}

\begin{itemize}
    \item Consulta de backlinks por URL;
    \item Estatísticas: termos mais pesquisados e tempo médio de resposta;
    \item Visualização de barrels ativos em tempo real;
    \item Dados persistentes entre reinícios;
    \item Crawlers executados em paralelo com threads independentes.
\end{itemize}





















\newpage
\section{Tolerância a Falhas e Confiabilidade}

O sistema foi concebido para manter a sua integridade e operabilidade mesmo perante falhas parciais ou interrupções temporárias. Foram implementados vários mecanismos que asseguram a continuidade dos serviços, a consistência dos dados e a recuperação automática em caso de falhas.

\subsection{Replicação Fiável entre Barrels}

Todos os \textit{storage barrels} mantêm cópias consistentes do índice invertido. Para garantir a coerência entre os nós, o processo de indexação recorre a \textbf{multicast atómico}: o \textit{WebCrawler} envia a página a todos os barrels e apenas considera a indexação concluída após todos confirmarem a receção. Esta abordagem assegura consistência mesmo em presença de falhas temporárias de comunicação.

\subsection{Recuperação de Estado}

Cada barrel persiste periodicamente os seus dados localmente em ficheiros \texttt{.ser} (binário) e \texttt{.txt} (legível). Ao reiniciar, o barrel tenta importar dados atualizados de outro barrel ativo através dos métodos \texttt{exportIndexData()} e \texttt{importIndexData()}. Na ausência de barrels disponíveis, carrega os dados locais salvos. Este processo de sincronização é realizado de forma assíncrona, sem bloquear o arranque do servidor.

\subsection{Alta Disponibilidade}

A \textit{SearchGateway} monitoriza dinamicamente o estado dos barrels. Caso um barrel esteja indisponível, os pedidos são automaticamente redirecionados para outro ativo. Esta redundância assegura que o sistema continua funcional desde que pelo menos um barrel esteja operacional, sem impacto para o utilizador.

\subsection{Distribuição de Carga}

As pesquisas são distribuídas entre os barrels de forma equilibrada com uma política de \textbf{round-robin}, implementada na gateway. Esta técnica contribui para a escalabilidade e evita sobrecarga de servidores específicos.

\subsection{Execução Concorrente de Crawlers}

A cada URL inserido na fila de indexação, é criado um novo \textit{WebCrawler} numa thread independente. Este paralelismo permite acelerar o processo de recolha e indexação de páginas, garantindo eficiência e utilização ótima dos recursos disponíveis.

\subsection{Resiliência da Gateway}

A \textit{SearchGateway} é projetada para continuar operacional independentemente do estado dos barrels. Quando todos os barrels estão offline, notifica o utilizador e permanece em execução, retomando automaticamente as funcionalidades normais assim que algum barrel se torne novamente acessível.




















\newpage
\section{RMI - Replicação e Multicast Fiável}

A replicação entre barrels segue o princípio de \textbf{multicast atómico}:
\begin{itemize} \item O \texttt{WebCrawler} envia cada nova página para todos os barrels ativos através de chamadas RMI ao método \texttt{indexPage()}.
\item A indexação só é considerada completa após todos os barrels confirmarem sucesso. Isto é implementado no ciclo com verificação de \texttt{confirmed.contains(address)} na classe \texttt{WebCrawler}.

\item Em caso de falha de comunicação com um barrel, é feito \texttt{retry} com \texttt{Thread.sleep(1000)} até obter sucesso.

\item Quando um barrel reinicia, importa o estado de outro barrel usando \texttt{exportIndexData()} e \texttt{importIndexData()}. Ver exemplo na classe \texttt{IndexStorageBarrel1}:
\begin{lstlisting}[language=Java, caption={Interface remota SearchService}]
    InvertedIndex.IndexData data = other.exportIndexData(); 
    index.importIndexData(data);
\end{lstlisting}
\end{itemize}













\newpage
\section{Interfaces RMI e Componentes Distribuídos}

O sistema utiliza RMI para permitir que os objetos distribuídos comuniquem entre si de forma transparente:

\begin{itemize} \item \texttt{SearchGateway}: utilizado pelo cliente. Define métodos como \texttt{search()}, \texttt{getTopSearches()}, \texttt{getActiveBarrels()}.
\item \texttt{SearchService}: implementado pelos barrels. Inclui os métodos \texttt{indexPage()}, \texttt{search()}, \texttt{getBacklinks()}, \texttt{exportIndexData()}, entre outros.

\item \texttt{CentralURLQueue}: usado pelos crawlers. Expõe \texttt{getNextUrl()} e \texttt{addUrl()}.

\item Os métodos RMI estão protegidos por \texttt{synchronized}, garantindo concorrência segura (ex: \texttt{public synchronized void indexPage(...)}).

\item Todos os acessos remotos são protegidos com blocos \texttt{try/catch} e os servidores utilizam \texttt{Naming.rebind()} para registo.
\end{itemize}


\subsection*{Exemplo de JAVA RMI: Interface remota \texttt{SearchService.java}}

O sistema utiliza \textbf{Java RMI (Remote Method Invocation)} como base para a comunicação entre os seus componentes. Cada serviço define uma interface remota que é implementada e registada num servidor. Seguem exemplos reais da implementação.

\begin{lstlisting}[language=Java, caption={Interface remota SearchService}]
public interface SearchService extends Remote {
    void indexPage(String url, String content) throws RemoteException;
    List<String> search(String term) throws RemoteException;
    Set<String> getBacklinks(String url) throws RemoteException;
    IndexData exportIndexData() throws RemoteException;
}
\end{lstlisting}







\newpage
\section{Exemplo Prático de Execução do Sistema}
\subsection{Iniciar o Sistema}

\begin{enumerate}
    \item Abrir um terminal na raiz do projeto.
    \item Executar o seguinte comando:
\end{enumerate}

\begin{lstlisting}[language=bash]
.\run.bat
\end{lstlisting}

Este script compila e inicia todos os componentes em terminais separados: fila central, gateway, barrels, cliente e crawler.

\subsection{Adicionar um URL para Indexação}

No terminal do cliente \texttt{SearchClient}, o menu apresenta várias opções. O utilizador escolhe a opção \texttt{4}:

Uma nova janela é aberta com o programa \texttt{LinkAdder}. O utilizador introduz um link, por exemplo:

\begin{lstlisting}
Enter URL to index: https://en.wikipedia.org/wiki/Distributed_computing
\end{lstlisting}

Este link é enviado para a fila central. Um \texttt{WebCrawler} é lançado automaticamente numa nova thread, e começa a processar o conteúdo da página.

Nos terminais dos barrels, surgem mensagens como:

\begin{lstlisting}
[Barrel][Indexing] https://en.wikipedia.org/wiki/Distributed_computing
[Barrel][Backlink] Registered: https://en.wikipedia.org/... -> ...
\end{lstlisting}

\subsection{Pesquisar um Termo}

De volta ao \texttt{SearchClient}, o utilizador escolhe a opção \texttt{1} para realizar uma pesquisa:

\begin{lstlisting}
Choose an option: 1
Enter search term: distributed
\end{lstlisting}

O sistema apresenta os resultados paginados (10 por página), ordenados por número de backlinks:

\begin{lstlisting}
Results [1–10] of 23:
1. https://en.wikipedia.org/wiki/Distributed_computing
2. https://en.wikipedia.org/wiki/Cloud_computing
...
Type 'n' for next page or 'q' to quit:
\end{lstlisting}

\subsection{Estatísticas e Funcionalidades Extra}

O utilizador pode ainda ver os termos mais pesquisados e o tempo médio de resposta, consultar backlinks de uma URL, etc.

\subsection{Encerrar o Sistema}

Todos os componentes podem ser encerrados manualmente ou fechando as janelas de terminal. Os barrels guardam automaticamente os dados em ficheiros \texttt{.ser} e \texttt{.txt}, garantindo persistência.













\newpage
\section{Divisão de Trabalho}
\begin{itemize}
    \item \textbf{Carlos Soares}:   Downloaders (WebCrawler) e  componente multicast fiável dos Barrels.
    \item \textbf{Miguel Machado}: Gateway e componente RPC/RMI dos Barrels.
    \item \textbf{Ambos}: Relatório e código em geral.
\end{itemize}






\newpage

\newpage
\section{Tabela de Testes}

\subsection{Gateway}

\begin{tabularx}{\textwidth}{X l}
\toprule
\textbf{Descrição} & \textbf{Resultado} \\
\midrule
Conexão RMI em localhost & Passou \\
Conexão RMI entre diferentes máquinas & Falhou \\
Ligar/Desligar barrels e confirmar atualização de estados & Falhou \\
Múltiplos clientes conectados simultaneamente & Falhou \\
Pedidos de menu (Cliente → Gateway → Downloader / URLQueue / ISB) & Passou \\
Balanceamento de carga entre barrels & Passou \\
Redirecionamento de pedidos em caso de falha & Passou \\
\bottomrule
\end{tabularx}

\vspace{1em}
\subsection{Downloader}

\begin{tabularx}{\textwidth}{X l}
\toprule
\textbf{Descrição} & \textbf{Resultado} \\
\midrule
Integração URLQueue → adicionar e consumir da fila & Passou \\
Indexação de URL & Passou \\
Indexação recursiva (exploração de links internos) & Passou \\
Integração com ISB & Passou \\
Execução concorrente e multithreading & Passou \\
Particionamento do índice / mensagens entre barrels & Falhou \\
Envio via multicast para todos os barrels & Passou \\
\bottomrule
\end{tabularx}

\vspace{1em}
\subsection{IndexStorageBarrel (ISB)}

\begin{tabularx}{\textwidth}{X l}
\toprule
\textbf{Descrição} & \textbf{Resultado} \\
\midrule
Resultados de pesquisa ordenados por backlinks & Passou \\
Integração com Downloader e sincronização via multicast & Passou \\
Stress test com múltiplos downloaders & Passou \\
Comunicação Cliente → Gateway → ISB & Passou \\
Deteção de falhas ou perda de pacotes & Falhou \\
Vários barrels ativos em simultâneo de forma correta & Passou \\
Recuperação de dados após falha e reinício de um barrel & Passou \\
\bottomrule
\end{tabularx}

\vspace{1em}
\subsection{URLQueue}

\begin{tabularx}{\textwidth}{X l}
\toprule
\textbf{Descrição} & \textbf{Resultado} \\
\midrule
Integração com Gateway e Downloaders (conexão + RMI) & Passou \\
Concorrência / bloqueios: evitar duplicações e condições de corrida & Passou \\
\bottomrule
\end{tabularx}

\vspace{1em}
\subsection{Cliente}

\begin{tabularx}{\textwidth}{X l}
\toprule
\textbf{Descrição} & \textbf{Resultado} \\
\midrule
Conexão via RMI à Gateway & Passou \\
Página de administração (menu) atualizada em tempo real & Passou \\
Testes de input/output e navegação no menu & Passou \\
\bottomrule
\end{tabularx}










\newpage
\section{Conclusão e Considerações Finais}

O sistema desenvolvido cumpre os objetivos propostos para a Meta 1, incluindo indexação recursiva, pesquisa distribuída, tolerância a falhas, concorrência e persistência de dados. A arquitetura modular baseada em RMI demonstrou-se eficaz e extensível, e o sistema comportou-se corretamente em testes com múltiplos crawlers e falhas simuladas.

Durante o desenvolvimento, foram adotadas várias decisões técnicas que reforçaram a robustez do sistema:

\begin{itemize}
    \item \textbf{Multicast atómico na indexação}: A indexação é considerada concluída apenas após todos os barrels confirmarem receção, garantindo consistência entre réplicas.

    \item \textbf{Sincronização assíncrona entre barrels}: A recuperação de estado após falha é feita em background, permitindo arranque rápido mesmo com falhas temporárias.

    \item \textbf{Evitar RMI em blocos sincronizados}: As chamadas RMI foram mantidas fora de secções críticas para evitar \textit{deadlocks} e melhorar desempenho.

    \item \textbf{Logs com identificação por thread}: Permitiram validar o paralelismo entre crawlers e facilitaram a depuração.

    \item \textbf{Script \texttt{run.bat}}: Automatiza a compilação e arranque de todos os componentes, simplificando testes e utilização.

    \item \textbf{Persistência dual (\texttt{.ser} + \texttt{.txt})}: Além do armazenamento binário, é gerado um ficheiro de texto para verificação manual.

    \item \textbf{Modularização do \texttt{LinkAdder}}: Mantido como componente separado para facilitar testes e simplificar o cliente.

    \item \textbf{Lançamento de crawlers em threads dedicadas}: Garante concorrência real e escalabilidade na indexação de múltiplos URLs.
\end{itemize}

Estas opções, embora não obrigatórias, aumentaram a fiabilidade, clareza e desempenho do sistema, contribuindo para um projeto robusto e preparado para evolução futura.


\end{document}































